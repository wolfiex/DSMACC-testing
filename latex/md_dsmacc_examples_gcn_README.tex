This is a Tensor\+Flow implementation of Graph Convolutional Networks for the task of (semi-\/supervised) classification of nodes in a graph, as described in our paper\+:

Thomas N. Kipf, Max Welling, \href{http://arxiv.org/abs/1609.02907}{\tt Semi-\/\+Supervised Classification with Graph Convolutional Networks} (I\+C\+LR 2017)

For a high-\/level explanation, have a look at our blog post\+:

Thomas Kipf, \href{http://tkipf.github.io/graph-convolutional-networks/}{\tt Graph Convolutional Networks} (2016)

\subsection*{Installation}


\begin{DoxyCode}
python setup.py install
\end{DoxyCode}


\subsection*{Requirements}


\begin{DoxyItemize}
\item tensorflow ($>$0.\+12)
\item networkx
\end{DoxyItemize}

\subsection*{Run the demo}


\begin{DoxyCode}
cd gcn
python train.py
\end{DoxyCode}


\subsection*{Data}

In order to use your own data, you have to provide
\begin{DoxyItemize}
\item an N by N adjacency matrix (N is the number of nodes),
\item an N by D feature matrix (D is the number of features per node), and
\item an N by E binary label matrix (E is the number of classes).
\end{DoxyItemize}

Have a look at the {\ttfamily load\+\_\+data()} function in {\ttfamily utils.\+py} for an example.

In this example, we load citation network data (Cora, Citeseer or Pubmed). The original datasets can be found here\+: \href{http://linqs.cs.umd.edu/projects/projects/lbc/}{\tt http\+://linqs.\+cs.\+umd.\+edu/projects/projects/lbc/}. In our version (see {\ttfamily data} folder) we use dataset splits provided by \href{https://github.com/kimiyoung/planetoid}{\tt https\+://github.\+com/kimiyoung/planetoid} (Zhilin Yang, William W. Cohen, Ruslan Salakhutdinov, \href{https://arxiv.org/abs/1603.08861}{\tt Revisiting Semi-\/\+Supervised Learning with Graph Embeddings}, I\+C\+ML 2016).

You can specify a dataset as follows\+:


\begin{DoxyCode}
python train.py --dataset citeseer
\end{DoxyCode}


(or by editing {\ttfamily train.\+py})

\subsection*{Models}

You can choose between the following models\+:
\begin{DoxyItemize}
\item {\ttfamily gcn}\+: Graph convolutional network (Thomas N. Kipf, Max Welling, \href{http://arxiv.org/abs/1609.02907}{\tt Semi-\/\+Supervised Classification with Graph Convolutional Networks}, 2016)
\item {\ttfamily gcn\+\_\+cheby}\+: Chebyshev polynomial version of graph convolutional network as described in (MichaÃ«l Defferrard, Xavier Bresson, Pierre Vandergheynst, \href{https://arxiv.org/abs/1606.09375}{\tt Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering}, N\+I\+PS 2016)
\item {\ttfamily dense}\+: Basic multi-\/layer perceptron that supports sparse inputs
\end{DoxyItemize}

\subsection*{Graph classification}

Our framework also supports batch-\/wise classification of multiple graph instances (of potentially different size) with an adjacency matrix each. It is best to concatenate respective feature matrices and build a (sparse) block-\/diagonal matrix where each block corresponds to the adjacency matrix of one graph instance. For pooling (in case of graph-\/level outputs as opposed to node-\/level outputs) it is best to specify a simple pooling matrix that collects features from their respective graph instances, as illustrated below\+:



\subsection*{Cite}

Please cite our paper if you use this code in your own work\+:


\begin{DoxyCode}
@inproceedings\{kipf2017semi,
  title=\{Semi-Supervised Classification with Graph Convolutional Networks\},
  author=\{Kipf, Thomas N. and Welling, Max\},
  booktitle=\{International Conference on Learning Representations (ICLR)\},
  year=\{2017\}
\}
\end{DoxyCode}
 