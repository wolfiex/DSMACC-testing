This is a Tensor\+Flow implementation of the (Variational) Graph Auto-\/\+Encoder model as described in our paper\+:

T. N. Kipf, M. Welling, \href{https://arxiv.org/abs/1611.07308}{\tt Variational Graph Auto-\/\+Encoders}, N\+I\+PS Workshop on Bayesian Deep Learning (2016)

Graph Auto-\/\+Encoders (G\+A\+Es) are end-\/to-\/end trainable neural network models for unsupervised learning, clustering and link prediction on graphs.



G\+A\+Es have successfully been used for\+:
\begin{DoxyItemize}
\item \mbox{\hyperlink{structLink}{Link}} prediction in large-\/scale relational data\+: M. Schlichtkrull \& T. N. Kipf et al., \href{https://arxiv.org/abs/1703.06103}{\tt Modeling Relational Data with Graph Convolutional Networks} (2017),
\item Matrix completion / recommendation with side information\+: R. Berg et al., \href{https://arxiv.org/abs/1706.02263}{\tt Graph Convolutional Matrix Completion} (2017).
\end{DoxyItemize}

G\+A\+Es are based on Graph Convolutional Networks (G\+C\+Ns), a recent class of models for end-\/to-\/end (semi-\/)supervised learning on graphs\+:

T. N. Kipf, M. Welling, \href{https://arxiv.org/abs/1609.02907}{\tt Semi-\/\+Supervised Classification with Graph Convolutional Networks}, I\+C\+LR (2017).

A high-\/level introduction is given in our blog post\+:

Thomas Kipf, \href{http://tkipf.github.io/graph-convolutional-networks/}{\tt Graph Convolutional Networks} (2016)

\subsection*{Installation}


\begin{DoxyCode}
python setup.py install
\end{DoxyCode}


\subsection*{Requirements}


\begin{DoxyItemize}
\item Tensor\+Flow (1.\+0 or later)
\item python 2.\+7
\item networkx
\item scikit-\/learn
\item scipy
\end{DoxyItemize}

\subsection*{Run the demo}


\begin{DoxyCode}
python train.py
\end{DoxyCode}


\subsection*{Data}

In order to use your own data, you have to provide
\begin{DoxyItemize}
\item an N by N adjacency matrix (N is the number of nodes), and
\item an N by D feature matrix (D is the number of features per node) -- optional
\end{DoxyItemize}

Have a look at the {\ttfamily load\+\_\+data()} function in {\ttfamily input\+\_\+data.\+py} for an example.

In this example, we load citation network data (Cora, Citeseer or Pubmed). The original datasets can be found here\+: \href{http://linqs.cs.umd.edu/projects/projects/lbc/}{\tt http\+://linqs.\+cs.\+umd.\+edu/projects/projects/lbc/} and here (in a different format)\+: \href{https://github.com/kimiyoung/planetoid}{\tt https\+://github.\+com/kimiyoung/planetoid}

You can specify a dataset as follows\+:


\begin{DoxyCode}
python train.py --dataset citeseer
\end{DoxyCode}


(or by editing {\ttfamily train.\+py})

\subsection*{Models}

You can choose between the following models\+:
\begin{DoxyItemize}
\item {\ttfamily gcn\+\_\+ae}\+: Graph Auto-\/\+Encoder (with G\+CN encoder)
\item {\ttfamily gcn\+\_\+vae}\+: Variational Graph Auto-\/\+Encoder (with G\+CN encoder)
\end{DoxyItemize}

\subsection*{Cite}

Please cite our paper if you use this code in your own work\+:


\begin{DoxyCode}
@article\{kipf2016variational,
  title=\{Variational Graph Auto-Encoders\},
  author=\{Kipf, Thomas N and Welling, Max\},
  journal=\{NIPS Workshop on Bayesian Deep Learning\},
  year=\{2016\}
\}
\end{DoxyCode}
 